{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20ca369-fee0-4083-b303-5a39a068ea5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import logging\n",
    "import calendar\n",
    "\n",
    "headers = {'User-Agent': \"Fgeating@gmail.com\"}\n",
    "# edit the ticker variable to call the security you want data for\n",
    "ticker = 'JPM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0dd1aebb-1be8-42e8-8d22-72eb594e0343",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = (\n",
    "    lambda x: \"{:,.0f}\".format(x) if int(x) == x else \"{:,.2f}\".format(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5ceb6002-0da8-4fb1-9ccc-79f1a03b45b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "statement_keys_map = {\n",
    "    \"balance_sheet\": [\n",
    "        \"balance sheet\",\n",
    "        \"balance sheets\",\n",
    "        \"statement of financial position\",\n",
    "        \"consolidated balance sheets\",\n",
    "        \"consolidated balance sheet\",\n",
    "        \"consolidated financial position\",\n",
    "        \"consolidated balance sheets - southern\",\n",
    "        \"consolidated statements of financial position\",\n",
    "        \"consolidated statement of financial position\",\n",
    "        \"consolidated statements of financial condition\",\n",
    "        \"combined and consolidated balance sheet\",\n",
    "        \"condensed consolidated balance sheets\",\n",
    "        \"consolidated balance sheets, as of december 31\",\n",
    "        \"dow consolidated balance sheets\",\n",
    "        \"consolidated balance sheets (unaudited)\",\n",
    "    ],\n",
    "    \"income_statement\": [\n",
    "        \"income statement\",\n",
    "        \"income statements\",\n",
    "        \"statement of earnings (loss)\",\n",
    "        \"statements of consolidated income\",\n",
    "        \"consolidated statements of operations\",\n",
    "        \"consolidated statement of operations\",\n",
    "        \"consolidated statements of earnings\",\n",
    "        \"consolidated statement of earnings\",\n",
    "        \"consolidated statements of income\",\n",
    "        \"consolidated statement of income\",\n",
    "        \"consolidated income statements\",\n",
    "        \"consolidated income statement\",\n",
    "        \"condensed consolidated statements of earnings\",\n",
    "        \"consolidated results of operations\",\n",
    "        \"consolidated statements of income (loss)\",\n",
    "        \"consolidated statements of income - southern\",\n",
    "        \"consolidated statements of operations and comprehensive income\",\n",
    "        \"consolidated statements of comprehensive income\",\n",
    "    ],\n",
    "    \"cash_flow_statement\": [\n",
    "        \"cash flows statement\",\n",
    "        \"cash flows statements\",\n",
    "        \"statement of cash flows\",\n",
    "        \"statements of consolidated cash flows\",\n",
    "        \"consolidated statements of cash flows\",\n",
    "        \"consolidated statement of cash flows\",\n",
    "        \"consolidated statement of cash flow\",\n",
    "        \"consolidated cash flows statements\",\n",
    "        \"consolidated cash flow statements\",\n",
    "        \"condensed consolidated statements of cash flows\",\n",
    "        \"consolidated statements of cash flows (unaudited)\",\n",
    "        \"consolidated statements of cash flows - southern\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9de52d89-5836-4845-8ee9-cd1cd1a0aceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cik_matching_ticker(ticker, headers=headers):\n",
    "    ticker = ticker.upper().replace(\".\", \"-\")\n",
    "    ticker_json = requests.get(\n",
    "        \"https://www.sec.gov/files/company_tickers.json\", headers=headers\n",
    "    ).json()\n",
    "\n",
    "    for company in ticker_json.values():\n",
    "        if company[\"ticker\"] == ticker:\n",
    "            cik = str(company[\"cik_str\"]).zfill(10)\n",
    "            return cik\n",
    "    raise ValueError(f\"Ticker {ticker} not found in SEC database\")\n",
    "\n",
    "# cik = cik_matching_ticker(ticker, headers=headers)\n",
    "# cik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b01d8572-baf9-408d-9576-1e61d43a164a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_submission_data_for_ticker(ticker, headers=headers, recent_filings_df=False):\n",
    "    \"\"\"\n",
    "    Get the data in json form for a given ticker. For example: 'cik', 'entityType', 'sic', 'sicDescription', 'insiderTransactionForOwnerExists', 'insiderTransactionForIssuerExists', 'name', 'tickers', 'exchanges', 'ein', 'description', 'website', 'investorWebsite', 'category', 'fiscalYearEnd', 'stateOfIncorporation', 'stateOfIncorporationDescription', 'addresses', 'phone', 'flags', 'formerNames', 'filings'\n",
    "\n",
    "    Args:\n",
    "        ticker (str): The ticker symbol of the company.\n",
    "\n",
    "    Returns:\n",
    "        json: The submissions for the company.\n",
    "    \"\"\"\n",
    "    cik = cik_matching_ticker(ticker)\n",
    "    headers = headers\n",
    "    url = f\"https://data.sec.gov/submissions/CIK{cik}.json\"\n",
    "    company_json = requests.get(url, headers=headers).json()\n",
    "    if recent_filings_df:\n",
    "        return pd.DataFrame(company_json[\"filings\"][\"recent\"])\n",
    "    else:\n",
    "        return company_json\n",
    "\n",
    "\n",
    "# company_json = get_submission_data_for_ticker(ticker, headers=headers, recent_filings_df=True)\n",
    "# company_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d8d18575-4391-4f30-ac0a-7aa4c5f8b88c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_files_data_from_json(json_data):\n",
    "    files_list = json_data['filings']['files']\n",
    "    all_data = []\n",
    "\n",
    "    # Iterate over the list of files and fetch each one\n",
    "    for file_info in files_list:\n",
    "        file_name = file_info['name']\n",
    "        file_url = f\"https://data.sec.gov/submissions/{file_name}\"\n",
    "        \n",
    "        print(f\"Fetching data from {file_url}...\")\n",
    "        \n",
    "        response = requests.get(file_url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            file_data = response.json()\n",
    "            all_data.append(file_data)\n",
    "            print(f\"Fetched data from {file_name} successfully.\")\n",
    "        else:\n",
    "            print(f\"Failed to fetch data from {file_name}. HTTP Status Code: {response.status_code}\")\n",
    "    \n",
    "    # Combine all fetched data into a single DataFrame\n",
    "    combined_df = pd.concat([pd.json_normalize(data) for data in all_data], ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "# Example usage\n",
    "# company_json = get_submission_data_for_ticker(ticker, headers=headers, recent_filings_df=False)\n",
    "\n",
    "# # Fetch and combine data from all files listed in the JSON data\n",
    "# combined_df = get_files_data_from_json(company_json)\n",
    "# combined_dff = pd.DataFrame(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6d0fe379-10ec-4ff8-b2bf-ec3c07330a5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-001.json...\n",
      "Fetched data from CIK0000019617-submissions-001.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-002.json...\n",
      "Fetched data from CIK0000019617-submissions-002.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-003.json...\n",
      "Fetched data from CIK0000019617-submissions-003.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-004.json...\n",
      "Fetched data from CIK0000019617-submissions-004.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-005.json...\n",
      "Fetched data from CIK0000019617-submissions-005.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-006.json...\n",
      "Fetched data from CIK0000019617-submissions-006.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-007.json...\n",
      "Fetched data from CIK0000019617-submissions-007.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-008.json...\n",
      "Fetched data from CIK0000019617-submissions-008.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-009.json...\n",
      "Fetched data from CIK0000019617-submissions-009.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-010.json...\n",
      "Fetched data from CIK0000019617-submissions-010.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-011.json...\n",
      "Fetched data from CIK0000019617-submissions-011.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-012.json...\n",
      "Fetched data from CIK0000019617-submissions-012.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-013.json...\n",
      "Fetched data from CIK0000019617-submissions-013.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-014.json...\n",
      "Fetched data from CIK0000019617-submissions-014.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-015.json...\n",
      "Fetched data from CIK0000019617-submissions-015.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-016.json...\n",
      "Fetched data from CIK0000019617-submissions-016.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-017.json...\n",
      "Fetched data from CIK0000019617-submissions-017.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-018.json...\n",
      "Fetched data from CIK0000019617-submissions-018.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-019.json...\n",
      "Fetched data from CIK0000019617-submissions-019.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-020.json...\n",
      "Fetched data from CIK0000019617-submissions-020.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-021.json...\n",
      "Fetched data from CIK0000019617-submissions-021.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-022.json...\n",
      "Fetched data from CIK0000019617-submissions-022.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-023.json...\n",
      "Fetched data from CIK0000019617-submissions-023.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-024.json...\n",
      "Fetched data from CIK0000019617-submissions-024.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-025.json...\n",
      "Fetched data from CIK0000019617-submissions-025.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-026.json...\n",
      "Fetched data from CIK0000019617-submissions-026.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-027.json...\n",
      "Fetched data from CIK0000019617-submissions-027.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-028.json...\n",
      "Fetched data from CIK0000019617-submissions-028.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-029.json...\n",
      "Fetched data from CIK0000019617-submissions-029.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-030.json...\n",
      "Fetched data from CIK0000019617-submissions-030.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-031.json...\n",
      "Fetched data from CIK0000019617-submissions-031.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-032.json...\n",
      "Fetched data from CIK0000019617-submissions-032.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-033.json...\n",
      "Fetched data from CIK0000019617-submissions-033.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-034.json...\n",
      "Fetched data from CIK0000019617-submissions-034.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-035.json...\n",
      "Fetched data from CIK0000019617-submissions-035.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-036.json...\n",
      "Fetched data from CIK0000019617-submissions-036.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-037.json...\n",
      "Fetched data from CIK0000019617-submissions-037.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-038.json...\n",
      "Fetched data from CIK0000019617-submissions-038.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-039.json...\n",
      "Fetched data from CIK0000019617-submissions-039.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-040.json...\n",
      "Fetched data from CIK0000019617-submissions-040.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-041.json...\n",
      "Fetched data from CIK0000019617-submissions-041.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-042.json...\n",
      "Fetched data from CIK0000019617-submissions-042.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-043.json...\n",
      "Fetched data from CIK0000019617-submissions-043.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-044.json...\n",
      "Fetched data from CIK0000019617-submissions-044.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-045.json...\n",
      "Fetched data from CIK0000019617-submissions-045.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-046.json...\n",
      "Fetched data from CIK0000019617-submissions-046.json successfully.\n",
      "Fetching data from https://data.sec.gov/submissions/CIK0000019617-submissions-047.json...\n",
      "Fetched data from CIK0000019617-submissions-047.json successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accessionNumber</th>\n",
       "      <th>filingDate</th>\n",
       "      <th>reportDate</th>\n",
       "      <th>acceptanceDateTime</th>\n",
       "      <th>act</th>\n",
       "      <th>form</th>\n",
       "      <th>fileNumber</th>\n",
       "      <th>filmNumber</th>\n",
       "      <th>items</th>\n",
       "      <th>size</th>\n",
       "      <th>isXBRL</th>\n",
       "      <th>isInlineXBRL</th>\n",
       "      <th>primaryDocument</th>\n",
       "      <th>primaryDocDescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001839882-24-018018</td>\n",
       "      <td>2024-06-05</td>\n",
       "      <td></td>\n",
       "      <td>2024-06-05T15:43:19.000Z</td>\n",
       "      <td>33</td>\n",
       "      <td>424B2</td>\n",
       "      <td>333-270004</td>\n",
       "      <td>241021847</td>\n",
       "      <td></td>\n",
       "      <td>1071141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>jpm_424b2-10814.htm</td>\n",
       "      <td>PRELIMINARY PRICING SUPPLEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001213900-24-050035</td>\n",
       "      <td>2024-06-05</td>\n",
       "      <td></td>\n",
       "      <td>2024-06-05T15:43:36.000Z</td>\n",
       "      <td>33</td>\n",
       "      <td>424B2</td>\n",
       "      <td>333-270004</td>\n",
       "      <td>241021850</td>\n",
       "      <td></td>\n",
       "      <td>147699</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ea175528_424b2.htm</td>\n",
       "      <td>PRELIMINARY PRICING SUPPLEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001213900-24-050034</td>\n",
       "      <td>2024-06-05</td>\n",
       "      <td></td>\n",
       "      <td>2024-06-05T15:40:33.000Z</td>\n",
       "      <td>33</td>\n",
       "      <td>424B2</td>\n",
       "      <td>333-270004</td>\n",
       "      <td>241021832</td>\n",
       "      <td></td>\n",
       "      <td>269109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ea175506_424b2.htm</td>\n",
       "      <td>PRELIMINARY PRICING SUPPLEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001213900-24-050030</td>\n",
       "      <td>2024-06-05</td>\n",
       "      <td></td>\n",
       "      <td>2024-06-05T15:37:09.000Z</td>\n",
       "      <td>33</td>\n",
       "      <td>424B2</td>\n",
       "      <td>333-270004</td>\n",
       "      <td>241021822</td>\n",
       "      <td></td>\n",
       "      <td>353427</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ea175516_424b2.htm</td>\n",
       "      <td>PRELIMINARY PRICING SUPPLEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001213900-24-050028</td>\n",
       "      <td>2024-06-05</td>\n",
       "      <td></td>\n",
       "      <td>2024-06-05T15:34:52.000Z</td>\n",
       "      <td>33</td>\n",
       "      <td>424B2</td>\n",
       "      <td>333-270004</td>\n",
       "      <td>241021807</td>\n",
       "      <td></td>\n",
       "      <td>332755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ea175515_424b2.htm</td>\n",
       "      <td>PRELIMINARY PRICING SUPPLEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19534</th>\n",
       "      <td>[0000891092-10-000242, 0000891092-10-000240, 0...</td>\n",
       "      <td>[2010-01-27, 2010-01-27, 2010-01-27, 2010-01-2...</td>\n",
       "      <td>[, , 2010-01-20, 2010-01-20, 2010-01-20, 2010-...</td>\n",
       "      <td>[2010-01-27T17:21:48.000Z, 2010-01-27T17:17:34...</td>\n",
       "      <td>[33, 33, , , , , , , , , , , , , , , , , , , ,...</td>\n",
       "      <td>[424B2, 424B2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4...</td>\n",
       "      <td>[333-155535, 333-155535, , , , , , , , , , , ,...</td>\n",
       "      <td>[10551375, 10551353, , , , , , , , , , , , , ,...</td>\n",
       "      <td>[, , , , , , , , , , , , , , , , , , , , , , ,...</td>\n",
       "      <td>[518310, 708434, 5006, 5014, 4963, 5562, 4874,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[e37609_424b2.htm, e37608_424b2.htm, xslF345X0...</td>\n",
       "      <td>[PRICING SUPPLEMENT NO. 414, PRICING SUPPLEMEN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19535</th>\n",
       "      <td>[0000891092-08-004250, 0000905148-08-003632, 0...</td>\n",
       "      <td>[2008-08-27, 2008-08-27, 2008-08-27, 2008-08-2...</td>\n",
       "      <td>[, 2008-08-25, , , , , , 2008-08-22, , 2008-08...</td>\n",
       "      <td>[2008-08-27T17:27:15.000Z, 2008-08-27T11:08:14...</td>\n",
       "      <td>[34, 34, 33, 33, 34, 33, 33, 34, 33, 34, 33, 3...</td>\n",
       "      <td>[FWP, 8-K, 424B2, 424B2, FWP, 424B2, 424B2, 8-...</td>\n",
       "      <td>[333-130051, 001-05805, 333-130051, 333-130051...</td>\n",
       "      <td>[081042842, 081040927, 081040870, 081040405, 0...</td>\n",
       "      <td>[, 9.01, , , , , , 9.01, , 9.01, , , 8.01, , ,...</td>\n",
       "      <td>[385994, 53887, 304157, 1921242, 308653, 27441...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[e32745fwp.htm, efc8-1208_form8k.htm, e32734_4...</td>\n",
       "      <td>[TERM SHEET, , PRICING SUPPLEMENT, PRODUCT SUP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19536</th>\n",
       "      <td>[0000950103-07-002774, 0000891092-07-005012, 0...</td>\n",
       "      <td>[2007-11-15, 2007-11-15, 2007-11-15, 2007-11-1...</td>\n",
       "      <td>[2007-11-14, , , , , , , , , , 2007-11-09, , 2...</td>\n",
       "      <td>[2007-11-15T16:53:36.000Z, 2007-11-15T16:38:19...</td>\n",
       "      <td>[34, 34, 34, 33, 33, 34, 34, 33, 33, 33, 34, 3...</td>\n",
       "      <td>[8-K, FWP, FWP, 424B2, 424B2, FWP, FWP, 424B3,...</td>\n",
       "      <td>[001-05805, 333-130051, 333-130051, 333-130051...</td>\n",
       "      <td>[071250353, 071250202, 071250167, 071250123, 0...</td>\n",
       "      <td>[9.01, , , , , , , , , , 9.01, , , , , , , , ,...</td>\n",
       "      <td>[41452, 438349, 336213, 572329, 16519, 687085,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[dp07590_8k.htm, e29277fwp.htm, e29278fwp.htm,...</td>\n",
       "      <td>[, TERM SHEET, AMENDED AND RESTATED TERM SHEET...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19537</th>\n",
       "      <td>[0000950103-06-002599, 0000891092-06-003533, 0...</td>\n",
       "      <td>[2006-11-14, 2006-11-14, 2006-11-14, 2006-11-1...</td>\n",
       "      <td>[2006-11-10, , , , , 2006-11-14, , 2006-11-09,...</td>\n",
       "      <td>[2006-11-14T17:02:44.000Z, 2006-11-14T16:54:15...</td>\n",
       "      <td>[34, 33, 33, 33, 33, 34, 34, 34, 33, 34, 34, 3...</td>\n",
       "      <td>[8-K, 424B2, 424B2, 424B2, 424B2, 8-K, FWP, 8-...</td>\n",
       "      <td>[001-05805, 333-130051, 333-130051, 333-130051...</td>\n",
       "      <td>[061216432, 061216220, 061216113, 061215932, 0...</td>\n",
       "      <td>[9.01, , , , , 7.01,9.01, , 9.01, , , , , , , ...</td>\n",
       "      <td>[33200, 546953, 264320, 460961, 235371, 949489...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[dp04009_8k.htm, e25587-424b2.htm, e25586_424b...</td>\n",
       "      <td>[, PRICING SUPPLEMENT, PRICING SUPPLEMENT, PRI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19538</th>\n",
       "      <td>[0000950123-03-009571, 0000019617-03-000424, 0...</td>\n",
       "      <td>[2003-08-19, 2003-08-19, 2003-08-19, 2003-08-1...</td>\n",
       "      <td>[, 2003-08-15, , 2003-08-13, 2003-08-12, 2003-...</td>\n",
       "      <td>[2003-08-19T15:00:57.000Z, 2003-08-19T11:30:16...</td>\n",
       "      <td>[, , , , , , , , , , , , , , , , , , , , , , ,...</td>\n",
       "      <td>[424B3, 4, S-3/A, 4, 4, 13F-HR, 4, 424B5, 10-Q...</td>\n",
       "      <td>[333-107207, , 333-107207, 000-22207, 000-2220...</td>\n",
       "      <td>[03855499, , 03854080, 03854237, 03847806, 038...</td>\n",
       "      <td>[, , , , , , , , , , , , , , , , , 5,7, , , , ...</td>\n",
       "      <td>[213669, 5342, 799909, 19860, 16031, 2323667, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[y89249e424b3.txt, xslF345X02/sre292.xml, y873...</td>\n",
       "      <td>[PROSPECTUS SUPPLEMENT, , AMENDMENT NO. 1 TO F...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19539 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         accessionNumber  \\\n",
       "0                                   0001839882-24-018018   \n",
       "1                                   0001213900-24-050035   \n",
       "2                                   0001213900-24-050034   \n",
       "3                                   0001213900-24-050030   \n",
       "4                                   0001213900-24-050028   \n",
       "...                                                  ...   \n",
       "19534  [0000891092-10-000242, 0000891092-10-000240, 0...   \n",
       "19535  [0000891092-08-004250, 0000905148-08-003632, 0...   \n",
       "19536  [0000950103-07-002774, 0000891092-07-005012, 0...   \n",
       "19537  [0000950103-06-002599, 0000891092-06-003533, 0...   \n",
       "19538  [0000950123-03-009571, 0000019617-03-000424, 0...   \n",
       "\n",
       "                                              filingDate  \\\n",
       "0                                             2024-06-05   \n",
       "1                                             2024-06-05   \n",
       "2                                             2024-06-05   \n",
       "3                                             2024-06-05   \n",
       "4                                             2024-06-05   \n",
       "...                                                  ...   \n",
       "19534  [2010-01-27, 2010-01-27, 2010-01-27, 2010-01-2...   \n",
       "19535  [2008-08-27, 2008-08-27, 2008-08-27, 2008-08-2...   \n",
       "19536  [2007-11-15, 2007-11-15, 2007-11-15, 2007-11-1...   \n",
       "19537  [2006-11-14, 2006-11-14, 2006-11-14, 2006-11-1...   \n",
       "19538  [2003-08-19, 2003-08-19, 2003-08-19, 2003-08-1...   \n",
       "\n",
       "                                              reportDate  \\\n",
       "0                                                          \n",
       "1                                                          \n",
       "2                                                          \n",
       "3                                                          \n",
       "4                                                          \n",
       "...                                                  ...   \n",
       "19534  [, , 2010-01-20, 2010-01-20, 2010-01-20, 2010-...   \n",
       "19535  [, 2008-08-25, , , , , , 2008-08-22, , 2008-08...   \n",
       "19536  [2007-11-14, , , , , , , , , , 2007-11-09, , 2...   \n",
       "19537  [2006-11-10, , , , , 2006-11-14, , 2006-11-09,...   \n",
       "19538  [, 2003-08-15, , 2003-08-13, 2003-08-12, 2003-...   \n",
       "\n",
       "                                      acceptanceDateTime  \\\n",
       "0                               2024-06-05T15:43:19.000Z   \n",
       "1                               2024-06-05T15:43:36.000Z   \n",
       "2                               2024-06-05T15:40:33.000Z   \n",
       "3                               2024-06-05T15:37:09.000Z   \n",
       "4                               2024-06-05T15:34:52.000Z   \n",
       "...                                                  ...   \n",
       "19534  [2010-01-27T17:21:48.000Z, 2010-01-27T17:17:34...   \n",
       "19535  [2008-08-27T17:27:15.000Z, 2008-08-27T11:08:14...   \n",
       "19536  [2007-11-15T16:53:36.000Z, 2007-11-15T16:38:19...   \n",
       "19537  [2006-11-14T17:02:44.000Z, 2006-11-14T16:54:15...   \n",
       "19538  [2003-08-19T15:00:57.000Z, 2003-08-19T11:30:16...   \n",
       "\n",
       "                                                     act  \\\n",
       "0                                                     33   \n",
       "1                                                     33   \n",
       "2                                                     33   \n",
       "3                                                     33   \n",
       "4                                                     33   \n",
       "...                                                  ...   \n",
       "19534  [33, 33, , , , , , , , , , , , , , , , , , , ,...   \n",
       "19535  [34, 34, 33, 33, 34, 33, 33, 34, 33, 34, 33, 3...   \n",
       "19536  [34, 34, 34, 33, 33, 34, 34, 33, 33, 33, 34, 3...   \n",
       "19537  [34, 33, 33, 33, 33, 34, 34, 34, 33, 34, 34, 3...   \n",
       "19538  [, , , , , , , , , , , , , , , , , , , , , , ,...   \n",
       "\n",
       "                                                    form  \\\n",
       "0                                                  424B2   \n",
       "1                                                  424B2   \n",
       "2                                                  424B2   \n",
       "3                                                  424B2   \n",
       "4                                                  424B2   \n",
       "...                                                  ...   \n",
       "19534  [424B2, 424B2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4...   \n",
       "19535  [FWP, 8-K, 424B2, 424B2, FWP, 424B2, 424B2, 8-...   \n",
       "19536  [8-K, FWP, FWP, 424B2, 424B2, FWP, FWP, 424B3,...   \n",
       "19537  [8-K, 424B2, 424B2, 424B2, 424B2, 8-K, FWP, 8-...   \n",
       "19538  [424B3, 4, S-3/A, 4, 4, 13F-HR, 4, 424B5, 10-Q...   \n",
       "\n",
       "                                              fileNumber  \\\n",
       "0                                             333-270004   \n",
       "1                                             333-270004   \n",
       "2                                             333-270004   \n",
       "3                                             333-270004   \n",
       "4                                             333-270004   \n",
       "...                                                  ...   \n",
       "19534  [333-155535, 333-155535, , , , , , , , , , , ,...   \n",
       "19535  [333-130051, 001-05805, 333-130051, 333-130051...   \n",
       "19536  [001-05805, 333-130051, 333-130051, 333-130051...   \n",
       "19537  [001-05805, 333-130051, 333-130051, 333-130051...   \n",
       "19538  [333-107207, , 333-107207, 000-22207, 000-2220...   \n",
       "\n",
       "                                              filmNumber  \\\n",
       "0                                              241021847   \n",
       "1                                              241021850   \n",
       "2                                              241021832   \n",
       "3                                              241021822   \n",
       "4                                              241021807   \n",
       "...                                                  ...   \n",
       "19534  [10551375, 10551353, , , , , , , , , , , , , ,...   \n",
       "19535  [081042842, 081040927, 081040870, 081040405, 0...   \n",
       "19536  [071250353, 071250202, 071250167, 071250123, 0...   \n",
       "19537  [061216432, 061216220, 061216113, 061215932, 0...   \n",
       "19538  [03855499, , 03854080, 03854237, 03847806, 038...   \n",
       "\n",
       "                                                   items  \\\n",
       "0                                                          \n",
       "1                                                          \n",
       "2                                                          \n",
       "3                                                          \n",
       "4                                                          \n",
       "...                                                  ...   \n",
       "19534  [, , , , , , , , , , , , , , , , , , , , , , ,...   \n",
       "19535  [, 9.01, , , , , , 9.01, , 9.01, , , 8.01, , ,...   \n",
       "19536  [9.01, , , , , , , , , , 9.01, , , , , , , , ,...   \n",
       "19537  [9.01, , , , , 7.01,9.01, , 9.01, , , , , , , ...   \n",
       "19538  [, , , , , , , , , , , , , , , , , 5,7, , , , ...   \n",
       "\n",
       "                                                    size  \\\n",
       "0                                                1071141   \n",
       "1                                                 147699   \n",
       "2                                                 269109   \n",
       "3                                                 353427   \n",
       "4                                                 332755   \n",
       "...                                                  ...   \n",
       "19534  [518310, 708434, 5006, 5014, 4963, 5562, 4874,...   \n",
       "19535  [385994, 53887, 304157, 1921242, 308653, 27441...   \n",
       "19536  [41452, 438349, 336213, 572329, 16519, 687085,...   \n",
       "19537  [33200, 546953, 264320, 460961, 235371, 949489...   \n",
       "19538  [213669, 5342, 799909, 19860, 16031, 2323667, ...   \n",
       "\n",
       "                                                  isXBRL  \\\n",
       "0                                                      0   \n",
       "1                                                      0   \n",
       "2                                                      0   \n",
       "3                                                      0   \n",
       "4                                                      0   \n",
       "...                                                  ...   \n",
       "19534  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "19535  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "19536  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "19537  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "19538  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                            isInlineXBRL  \\\n",
       "0                                                      0   \n",
       "1                                                      0   \n",
       "2                                                      0   \n",
       "3                                                      0   \n",
       "4                                                      0   \n",
       "...                                                  ...   \n",
       "19534  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "19535  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "19536  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "19537  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "19538  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                         primaryDocument  \\\n",
       "0                                    jpm_424b2-10814.htm   \n",
       "1                                     ea175528_424b2.htm   \n",
       "2                                     ea175506_424b2.htm   \n",
       "3                                     ea175516_424b2.htm   \n",
       "4                                     ea175515_424b2.htm   \n",
       "...                                                  ...   \n",
       "19534  [e37609_424b2.htm, e37608_424b2.htm, xslF345X0...   \n",
       "19535  [e32745fwp.htm, efc8-1208_form8k.htm, e32734_4...   \n",
       "19536  [dp07590_8k.htm, e29277fwp.htm, e29278fwp.htm,...   \n",
       "19537  [dp04009_8k.htm, e25587-424b2.htm, e25586_424b...   \n",
       "19538  [y89249e424b3.txt, xslF345X02/sre292.xml, y873...   \n",
       "\n",
       "                                   primaryDocDescription  \n",
       "0                         PRELIMINARY PRICING SUPPLEMENT  \n",
       "1                         PRELIMINARY PRICING SUPPLEMENT  \n",
       "2                         PRELIMINARY PRICING SUPPLEMENT  \n",
       "3                         PRELIMINARY PRICING SUPPLEMENT  \n",
       "4                         PRELIMINARY PRICING SUPPLEMENT  \n",
       "...                                                  ...  \n",
       "19534  [PRICING SUPPLEMENT NO. 414, PRICING SUPPLEMEN...  \n",
       "19535  [TERM SHEET, , PRICING SUPPLEMENT, PRODUCT SUP...  \n",
       "19536  [, TERM SHEET, AMENDED AND RESTATED TERM SHEET...  \n",
       "19537  [, PRICING SUPPLEMENT, PRICING SUPPLEMENT, PRI...  \n",
       "19538  [PROSPECTUS SUPPLEMENT, , AMENDMENT NO. 1 TO F...  \n",
       "\n",
       "[19539 rows x 14 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def entire_filing_history_combined(ticker, headers=headers):\n",
    "    # Recent filings DataFrame\n",
    "    recent_filings_df = get_submission_data_for_ticker(ticker, headers=headers, recent_filings_df=True)\n",
    "                                                      \n",
    "    # Historial filings DataFrame\n",
    "    company_json = get_submission_data_for_ticker(ticker, headers=headers, recent_filings_df=False)\n",
    "\n",
    "    # Fetch and combine data from all files listed in the JSON data\n",
    "    combined_df = get_files_data_from_json(company_json)\n",
    "    historical_filings_df = pd.DataFrame(combined_df)\n",
    "\n",
    "    # Combined DataFrames for entire filing history\n",
    "    df_merged = pd.concat([recent_filings_df, historical_filings_df], ignore_index=True, sort=False)\n",
    "    return df_merged\n",
    "\n",
    "df_merged = entire_filing_history_combined(ticker, headers=headers)\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a08afb83-420f-4bfa-a687-adefa3a68100",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_filtered_filings(\n",
    "    ticker, desired_forms=True, just_accession_numbers=False, headers=headers\n",
    "):\n",
    "    company_filings_df = entire_filing_history_combined(ticker, headers=headers)\n",
    "    if desired_forms:\n",
    "        # edit the desired_forms variable to include or exclude the filtered forms that you want\n",
    "        desired_forms = ['10-Q']\n",
    "        df = company_filings_df[company_filings_df[\"form\"].isin(desired_forms)]\n",
    "    else:\n",
    "        df = company_filings_df\n",
    "    if just_accession_numbers:\n",
    "        df = df.set_index(\"reportDate\")\n",
    "        accession_df = df[[\"accessionNumber\"]]\n",
    "        return accession_df\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "# soup = get_filtered_filings(ticker, desired_forms=True, just_accession_numbers=False, headers=headers)\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fe3075-a69d-48e8-8f4e-8427606193fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_facts(ticker, headers=headers):\n",
    "    cik = cik_matching_ticker(ticker)\n",
    "    url = f\"https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json\"\n",
    "    company_facts = requests.get(url, headers=headers).json()\n",
    "    return company_facts\n",
    "    \n",
    "company_facts = get_facts(ticker, headers=headers)\n",
    "company_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3bc3b1-7978-4dd2-a8c7-4c54b91bc68a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def facts_DF(ticker, headers=headers):\n",
    "    facts = get_facts(ticker, headers)\n",
    "    us_gaap_data = facts[\"facts\"][\"us-gaap\"]\n",
    "    df_data = []\n",
    "    for fact, details in us_gaap_data.items():\n",
    "        for unit in details[\"units\"]:\n",
    "            for item in details[\"units\"][unit]:\n",
    "                row = item.copy()\n",
    "                row[\"fact\"] = fact\n",
    "                df_data.append(row)\n",
    "        df = pd.DataFrame(df_data)\n",
    "    df[\"end\"] = pd.to_datetime(df[\"end\"])\n",
    "    df[\"start\"] = pd.to_datetime(df[\"start\"])\n",
    "    df = df.drop_duplicates(subset=[\"fact\", \"end\", \"val\"])\n",
    "    df.set_index(\"end\", inplace=True)\n",
    "    labels_dict = {fact: details[\"label\"] for fact, details in us_gaap_data.items()}\n",
    "    return df, labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3511736-e9d6-4601-97db-236988e8fadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annual_facts(ticker, headers=headers):\n",
    "    accession_nums = get_filtered_filings(\n",
    "        ticker, ten_k=True, just_accession_numbers=True\n",
    "    )\n",
    "    df, label_dict = facts_DF(ticker, headers)\n",
    "    ten_k = df[df[\"accn\"].isin(accession_nums)]\n",
    "    ten_k = ten_k[ten_k.index.isin(accession_nums.index)]\n",
    "    pivot = ten_k.pivot_table(values=\"val\", columns=\"fact\", index=\"end\")\n",
    "    pivot.rename(columns=label_dict, inplace=True)\n",
    "    return pivot.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eb231c-c5ba-4bbd-8b6f-690ecddfc54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quarterly_facts(ticker, headers=headers):\n",
    "    accession_nums = get_filtered_filings(\n",
    "        ticker, ten_k=False, just_accession_numbers=True\n",
    "    )\n",
    "    df, label_dict = facts_DF(ticker, headers)\n",
    "    ten_q = df[df[\"accn\"].isin(accession_nums)]\n",
    "    ten_q = ten_q[ten_q.index.isin(accession_nums.index)].reset_index(drop=False)\n",
    "    ten_q = ten_q.drop_duplicates(subset=[\"fact\", \"end\"], keep=\"last\")\n",
    "    pivot = ten_q.pivot_table(values=\"val\", columns=\"fact\", index=\"end\")\n",
    "    pivot.rename(columns=label_dict, inplace=True)\n",
    "    return pivot.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d41615d-5370-40d0-ac6c-a2b416b7f298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe_to_csv(dataframe, folder_name, ticker, statement_name, frequency):\n",
    "    directory_path = os.path.join(folder_name, ticker)\n",
    "    os.makedirs(directory_path, exist_ok=True)\n",
    "    file_path = os.path.join(directory_path, f\"{statement_name}_{frequency}.csv\")\n",
    "    dataframe.to_csv(file_path)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a127cc-e1c9-4e78-8e57-26f7febf2af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_file_name(report):\n",
    "    html_file_name_tag = report.find(\"HtmlFileName\")\n",
    "    xml_file_name_tag = report.find(\"XmlFileName\")\n",
    "\n",
    "    if html_file_name_tag:\n",
    "        return html_file_name_tag.text\n",
    "    elif xml_file_name_tag:\n",
    "        return xml_file_name_tag.text\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2a09f1-b3bb-42b8-afee-6bd479cb3ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _is_statement_file(short_name_tag, long_name_tag, file_name):\n",
    "    return (\n",
    "        short_name_tag is not None\n",
    "        and long_name_tag is not None\n",
    "        and file_name  # Check if file_name is not an empty string\n",
    "        and \"Statement\" in long_name_tag.text\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b748de75-b5e8-48e8-bf5a-b6098c907e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statement_file_names_in_filing_summary(\n",
    "    ticker, accession_number, headers=headers\n",
    "):\n",
    "    try:\n",
    "        session = requests.Session()\n",
    "        cik = cik_matching_ticker(ticker)\n",
    "        \n",
    "        base_link = f\"https://www.sec.gov/Archives/edgar/data/{cik}/{accession_number}\"\n",
    "        filing_summary_link = f\"{base_link}/FilingSummary.xml\"\n",
    "        filing_summary_response = session.get(\n",
    "            filing_summary_link, headers=headers\n",
    "        ).content.decode(\"utf-8\")\n",
    "\n",
    "        filing_summary_soup = BeautifulSoup(filing_summary_response, \"lxml-xml\")\n",
    "        statement_file_names_dict = {}\n",
    "\n",
    "        for report in filing_summary_soup.find_all(\"Report\"):\n",
    "            file_name = _get_file_name(report)\n",
    "            short_name, long_name = report.find(\"ShortName\"), report.find(\"LongName\")\n",
    "\n",
    "            if _is_statement_file(short_name, long_name, file_name):\n",
    "                statement_file_names_dict[short_name.text.lower()] = file_name\n",
    "\n",
    "        return statement_file_names_dict\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65b7783-fec3-4cab-be64-0a79aa4c0e91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_statement_soup(\n",
    "    ticker,\n",
    "    accession_number,\n",
    "    statement_name,\n",
    "    headers,\n",
    "    statement_keys_map,\n",
    "):\n",
    "    \"\"\"\n",
    "    Retrieves the BeautifulSoup object for a speccific financial statement.\n",
    "\n",
    "    Args:\n",
    "        ticker(str): Stock ticker symbol.\n",
    "        accession_number (str): SEC filing accession number.\n",
    "        statment_name (str): has to be 'balance_sheet', 'income_statement', 'cash_flow_statement'\n",
    "        headers (dict): headers for HTTP request.\n",
    "        statement_keys_map (dict): Mapping of statement names to keys.\n",
    "\n",
    "    Returns:\n",
    "        BeautifulSoup: Parsed HTML/XML content of the financial statement.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the statement file name is not found or if there is an error fetcing the statement.\n",
    "        \n",
    "    the statement_name should be one of the following:\n",
    "    'balance_sheet'\n",
    "    'income_statement'\n",
    "    'cash_flow_statement'\n",
    "    \"\"\"\n",
    "    \n",
    "    session = requests.Session()\n",
    "    cik = cik_matching_ticker(ticker)\n",
    "    base_link = f\"https://www.sec.gov/Archives/edgar/data/{cik}/{accession_number}\"\n",
    "    # Get statement file names\n",
    "    statement_file_name_dict = get_statement_file_names_in_filing_summary(\n",
    "        ticker, accession_number, headers\n",
    "    )\n",
    "    statement_link = None\n",
    "    # Find the specific statement link\n",
    "    for possible_key in statement_keys_map.get(statement_name.lower(), []):\n",
    "        file_name = statement_file_name_dict.get(possible_key.lower())\n",
    "        if file_name:\n",
    "            statement_link = f\"{base_link}/{file_name}\"\n",
    "            break\n",
    "\n",
    "    if not statement_link:\n",
    "        raise ValueError(f\"Could not find statement file name for {statement_name}\")\n",
    "    # Fetch the statement\n",
    "    try:\n",
    "        statement_response = session.get(statement_link, headers=headers)\n",
    "        statement_response.raise_for_status()\n",
    "        \n",
    "        # Check if the request was successful\n",
    "\n",
    "        if statement_link.endswith(\".xml\"):\n",
    "            return BeautifulSoup(\n",
    "                statement_response.content, \"lxml-xml\", from_encoding=\"utf-8\"\n",
    "            )\n",
    "        else:\n",
    "            return BeautifulSoup(statement_response.content, \"lxml\")\n",
    "            print(statement_link)\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        raise ValueError(f\"Error fetching the statement: {e}\")\n",
    "        \n",
    "# accn = get_filtered_filings(ticker, eight_k=True, just_accession_numbers=True, headers=headers)\n",
    "# acc_num = accn.iloc[0]['accessionNumber'].replace('-','')\n",
    "# soup = get_statement_soup(\"JPM\", acc_num, 'balance_sheet', headers=headers, statement_keys_map=statement_keys_map)\n",
    "# accn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460db4c5-a780-4e36-b02f-7c4b71158f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetime_index_dates_from_statement(soup: BeautifulSoup) -> pd.DatetimeIndex:\n",
    "    \"\"\"\n",
    "    Extracts datetime index dates from the HTML soup object of a financial statement.\n",
    "\n",
    "    Args:\n",
    "        soup (BeautifulSoup): The BeautifulSoup object of the HTML document.\n",
    "\n",
    "    Returns:\n",
    "        pd.DatetimeIndex: A Pandas DatetimeIndex object containing the extracted dates.\n",
    "    \"\"\"\n",
    "    table_headers = soup.find_all(\"th\", {\"class\": \"th\"})\n",
    "    dates = [str(th.div.string) for th in table_headers if th.div and th.div.string]\n",
    "    dates = [standardize_date(date).replace(\".\", \"\") for date in dates]\n",
    "    # Convert standardized dates to datetime objects\n",
    "    try:\n",
    "        index_dates = pd.to_datetime(dates)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error converting dates to datetime: {e}\")\n",
    "        return pd.DatetimeIndex([])\n",
    "    \n",
    "    return index_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aab706-7454-4946-acd9-29120992d81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_date(date: str) -> str:\n",
    "    \"\"\"\n",
    "    Standardizes date strings by replacing abbreviations with full month names.\n",
    "\n",
    "    Args:\n",
    "        date (str): The date string to be standardized.\n",
    "\n",
    "    Returns:\n",
    "        str: The standardized date string.\n",
    "    \"\"\"\n",
    "    for abbr, full in zip(calendar.month_abbr[1:], calendar.month_name[1:]):\n",
    "        date = date.replace(abbr, full)\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504467e2-518e-47e8-87d9-24b6d250c6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_columns_values_and_dates_from_statement(soup):\n",
    "    \"\"\"\n",
    "    Extracts columns, values, and dates from HTML soup object representing a financial statment. \n",
    "\n",
    "    Args:\n",
    "        soup (BeautifulSoup): the BeautifulSoup object of the HTML document.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Tuple containing columns, values_set, and date_time_index.\n",
    "    \"\"\"\n",
    "    columns = []\n",
    "    values_set = []\n",
    "    date_time_index = get_datetime_index_dates_from_statement(soup)\n",
    "\n",
    "    for table in soup.find_all('table'):\n",
    "        unit_multiplier = 1\n",
    "        special_case = False\n",
    "\n",
    "        # Check table headers for unit multipliers and special cases\n",
    "        table_header = table.find('th')\n",
    "        if table_header:\n",
    "            header_text = table_header.get_text()\n",
    "            # Determine unit multiplier based on header text\n",
    "            if 'in Thousands' in header_text:\n",
    "                unit_muliplier = 1\n",
    "            elif 'in Millions' in header_text:\n",
    "                unit_muliplier = 1000\n",
    "            # check for special case senario\n",
    "            if 'unless otherqise specified' in header_text:\n",
    "                special_case = True\n",
    "\n",
    "                # Find all anchor elements with 'onclick' attribute\n",
    "                # onclick_elements = soup.select('td.pl a, td.pl.custom a')\n",
    "\n",
    "            # Process each row of the table\n",
    "            for row in table.select(\"tr\"):\n",
    "                onclick_elements = row.select(\"td.pl a, td.pl.custom a\")\n",
    "                if not onclick_elements:\n",
    "                    continue\n",
    "                \n",
    "            # Extract column title from 'onclick' attributeabs\n",
    "            onclick_attr = onclick_elements[0]['onclick']\n",
    "            column_title = onclick_attr.split('defref_')[-1].split(\"',\")[0]\n",
    "            columns.append(column_title)\n",
    "         \n",
    "            # Initialize values array with NaNs\n",
    "            values = [np.NaN] * len(date_time_index)\n",
    "\n",
    "            # Process each cell in the row\n",
    "            for i, cell in enumerate(row.select(\"td.text, td.nump, td.num\")):\n",
    "                if \"text\" in cell.get(\"class\"):\n",
    "                    continue\n",
    "\n",
    "                # Clean and parse cell value\n",
    "                value = keep_numbers_and_decimals_only_in_string(\n",
    "                    cell.text.replace(\"$\", \"\")\n",
    "                    .replace(\",\", \"\")\n",
    "                    .replace(\"(\", \"\")\n",
    "                    .replace(\")\", \"\")\n",
    "                    .strip()\n",
    "                )\n",
    "                if value:\n",
    "                    value = float(value)\n",
    "                    # Adjust value based on special case and cell class\n",
    "                    if special_case:\n",
    "                        value /= 1000\n",
    "                    else:\n",
    "                        if \"nump\" in cell.get(\"class\"):\n",
    "                            values[i] = value * unit_multiplier\n",
    "                        else:\n",
    "                            values[i] = -value * unit_multiplier\n",
    "\n",
    "            values_set.append(values)\n",
    "\n",
    "    return columns, values_set, date_time_index\n",
    "    \n",
    "accn = get_filtered_filings(ticker, desired_forms=False, just_accession_numbers=True, headers=headers)\n",
    "acc_num = accn.iloc[0]['accessionNumber'].replace('-','')\n",
    "soup = get_statement_soup(ticker, acc_num, 'balance_sheet', headers=headers, statement_keys_map=statement_keys_map)\n",
    "extract_columns_values_and_dates_from_statement(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117b00f3-2c1e-4688-be14-933f470171d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_numbers_and_decimals_only_in_string(mixed_string: str):\n",
    "    \"\"\"\n",
    "    Filters a string to keep only numbers and decimal points.\n",
    "\n",
    "    Args:\n",
    "        mixed_string (str): The string containing mixed characters.\n",
    "\n",
    "    Returns:\n",
    "        str: String containing only numbers and decimal points.\n",
    "    \"\"\"\n",
    "    num = \"1234567890.\"\n",
    "    allowed = list(filter(lambda x: x in num, mixed_string))\n",
    "    return \"\".join(allowed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca4cbf3-cd39-4fe3-a173-104bf3ec6282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe_of_statement_values_columns_dates(\n",
    "    values_set, columns, index_dates\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a DataFrame from statement values, columns, and index dates.\n",
    "\n",
    "    Args:\n",
    "        values_set (list): List of values for each column.\n",
    "        columns (list): List of column names.\n",
    "        index_dates (pd.DatetimeIndex): DatetimeIndex for the DataFrame index.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame constructed from the given data.\n",
    "    \"\"\"\n",
    "    transposed_values_set = list(zip(*values_set))\n",
    "    df = pd.DataFrame(transposed_values_set, columns=columns, index=index_dates)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2e3e1c-cbbe-4de8-a0cd-64f45b58669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_statement(ticker, accession_number, statement_name):\n",
    "    \"\"\"\n",
    "    Processes a single financial statement identified by ticker, accession number, and statement name.\n",
    "\n",
    "    Args:\n",
    "        ticker (str): The stock ticker.\n",
    "        accession_number (str): The SEC accession number.\n",
    "        statement_name (str): Name of the financial statement.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame or None: DataFrame of the processed statement or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Fetch the statement HTML soup\n",
    "        soup = get_statement_soup(\n",
    "            ticker,\n",
    "            accession_number,\n",
    "            statement_name,\n",
    "            headers=headers,\n",
    "            statement_keys_map=statement_keys_map,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logging.error(\n",
    "            f\"Failed to get statement soup: {e} for accession number: {accession_number}\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    if soup:\n",
    "        try:\n",
    "            # Extract data and create DataFrame\n",
    "            columns, values, dates = extract_columns_values_and_dates_from_statement(\n",
    "                soup\n",
    "            )\n",
    "            df = create_dataframe_of_statement_values_columns_dates(\n",
    "                values, columns, dates\n",
    "            )\n",
    "\n",
    "            if not df.empty:\n",
    "                # Remove duplicate columns\n",
    "                df = df.T.drop_duplicates()\n",
    "            else:\n",
    "                logging.warning(\n",
    "                    f\"Empty DataFrame for accession number: {accession_number}\"\n",
    "                )\n",
    "                return None\n",
    "\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing statement: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99093853-7a1b-4f9b-9f9a-c705d572da7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
